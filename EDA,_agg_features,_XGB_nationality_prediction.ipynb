{
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION  IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'big-five-personality-test:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F516764%2F951745%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240317%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240317T214136Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da0194cdfee4a3e86115f1f2cbd1dbf7653c902d7ccce5b7f351fe1e684717205ac833a9cc84ad4ceb1c24024c8466494d6a7ca99f88798faafc723432cff96f506ba81c0c07b642c042252935ab37692e9a0d277ea587597a84851a1f501d1aad6ceafcb53f86abd24227fc3e2d75c8ce6ead731496b5ee7bf5ef7b3fa1d842f83afaab294c393a8cd2a6d93fe6e52532a14efd6b67a18625f3c5cf9bec5ba00af5b4a927c87beaf2dfee769b31f1b50ae75cfecc5656de98c4373fa75272eb67d9b3afd271fb61f739f782d6ec307ca8949d1ed7ed797aa4faec2639c6847aab1d3826d31b9e94b53638b6c27a99e0288a169387faf56e1790233dac2e2fa70'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "cZ3n9xIyXPYf"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "onk0pLr1XPYn"
      },
      "cell_type": "markdown",
      "source": [
        "**See GitHub for summary findings:**\n",
        "[https://github.com/gajdulj/personalityanalysis](http://)\n",
        "\n",
        "**Associated Medium article: **\n",
        "[https://medium.com/@jakubgajdul/4-things-that-data-tells-us-about-our-personalities-210cdd8f71f](http://)"
      ]
    },
    {
      "metadata": {
        "id": "6izh2UlOXPYq"
      },
      "cell_type": "markdown",
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "unommvgQXPYr"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vsDPiGtBXPYs"
      },
      "cell_type": "code",
      "source": [
        "# Check the mpl version (3.1.1 causes issues with seaborn)\n",
        "matplotlib.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Bpwmf-P9XPYs"
      },
      "cell_type": "code",
      "source": [
        "# command for readable pandas formatting\n",
        "pd.options.display.float_format = \"{:.2f}\".format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "owoxQin2XPYt"
      },
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('../input/big-five-personality-test/IPIP-FFM-data-8Nov2018/data-final.csv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WbW5-X9nXPYu"
      },
      "cell_type": "markdown",
      "source": [
        "# INSPECT THE DATA"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "O5FpkdgaXPYv"
      },
      "cell_type": "code",
      "source": [
        "# Inspect the data\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dbrRjDUIXPYw"
      },
      "cell_type": "code",
      "source": [
        "# Inspect the metadata.\n",
        "df.info(verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "azvkqzM5XPYx"
      },
      "cell_type": "code",
      "source": [
        "# Inspect the data shape\n",
        "print('Number of rows:',df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YKgy2WJWXPYx"
      },
      "cell_type": "code",
      "source": [
        "# Classify the columns to categorical and numerical\n",
        "num_cols = df._get_numeric_data().columns\n",
        "cat_cols = [col for col in df.columns if col not in num_cols]\n",
        "print('Number of columns:',len(df.columns),\n",
        "      f' (numerical:{len(num_cols)},',\n",
        "      f' categorical:{len(cat_cols)})')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9A3-xyjYXPYy"
      },
      "cell_type": "markdown",
      "source": [
        "# CLEAN THE DATA"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1B6Aq6hqXPYy"
      },
      "cell_type": "code",
      "source": [
        "# First step of cleaning- IPC.\n",
        "# Limit the analysis to IPC =1 to get rid of duplicated submissions.\n",
        "\"\"\"\n",
        "As per Kaggle dataset description:\n",
        "The number of records from the user's IP address in the dataset.\n",
        "For max cleanliness, only use records where this value is 1.\n",
        "High values can be because of shared networks (e.g. entire universities) or multiple submissions\n",
        "\"\"\"\n",
        "df = df.loc[df['IPC']==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "h6FcGihOXPYz"
      },
      "cell_type": "code",
      "source": [
        "# Get rid of invalid results\n",
        "# As the answers are in scale 1 to 5, we want to delete invalid inputs\n",
        "df = df.loc[(df[df.columns.tolist()[:49]] >= 1).all(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JjcsJaLRXPYz"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature normalization"
      ]
    },
    {
      "metadata": {
        "id": "hh8ex2ymXPYz"
      },
      "cell_type": "markdown",
      "source": [
        "Credits: Tyler B https://www.kaggle.com/bluewizard/scoring-the-big-five-personality-test-items\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "22dNNYYIXPYz"
      },
      "cell_type": "code",
      "source": [
        "# positive questions adding to the trait.\n",
        "pos_questions = [\n",
        "    'EXT1','EXT3','EXT5','EXT7','EXT9',                       # 5\n",
        "    'EST1','EST3','EST5','EST6','EST7','EST8','EST9','EST10', # 8\n",
        "    'AGR2','AGR4','AGR6','AGR8','AGR9','AGR10',               # 6\n",
        "    'CSN1','CSN3','CSN5','CSN7','CSN9','CSN10',               # 6\n",
        "    'OPN1','OPN3','OPN5','OPN7','OPN8','OPN9','OPN10',        # 7\n",
        "]\n",
        "\n",
        "# negative (negating) questions subtracting from the trait.\n",
        "neg_questions = [\n",
        "    'EXT2','EXT4','EXT6','EXT8','EXT10', # 5\n",
        "    'EST2','EST4',                       # 2\n",
        "    'AGR1','AGR3','AGR5','AGR7',         # 4\n",
        "    'CSN2','CSN4','CSN6','CSN8',         # 4\n",
        "    'OPN2','OPN4','OPN6',                # 3\n",
        "]\n",
        "\n",
        "# Replace the question answer with -2 to 2 scale depending if the question is positive or negative.\n",
        "df[pos_questions] = df[pos_questions].replace({1:-2, 2:-1, 3:0, 4:1, 5:2})\n",
        "df[neg_questions] = df[neg_questions].replace({1:2, 2:1, 3:0, 4:-1, 5:-2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "6TZ5eDY0XPY0"
      },
      "cell_type": "code",
      "source": [
        "# Check for missing data.\n",
        "df.isna().mean().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bB1xpZNDXPY0"
      },
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df.isna().mean().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MBSqWiITXPY0"
      },
      "cell_type": "code",
      "source": [
        "# columns with time spent answering questions\n",
        "qtime_cols = list(df.columns)[50:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DQY5ZLUvXPY0"
      },
      "cell_type": "code",
      "source": [
        "# Check if selected correct columns\n",
        "qtime_cols[0], qtime_cols[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OQDgg-Q-XPY1"
      },
      "cell_type": "code",
      "source": [
        "# Calculate the total time for each survey\n",
        "df['total_time']=df[qtime_cols].sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "nncxx6pxXPY1"
      },
      "cell_type": "code",
      "source": [
        "df['total_time'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "BmbX98v7XPY1"
      },
      "cell_type": "code",
      "source": [
        "# Can't see anything due to large outliers\n",
        "ax = sns.distplot(df['total_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RZmqT0OnXPY1"
      },
      "cell_type": "code",
      "source": [
        "# See how much data will be lost if we get rid of the outliers\n",
        "total_respondents = len(df)\n",
        "fast_respondents = len(df[df['total_time']<10000])\n",
        "slow_respondents = len(df[df['total_time']>1000000])\n",
        "\n",
        "print(\"Total respondents:\",total_respondents)\n",
        "print(\"Slowest respondents:\",slow_respondents/total_respondents)\n",
        "print(\"Fastest respondents:\",fast_respondents/total_respondents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KMi1bI3AXPY2"
      },
      "cell_type": "code",
      "source": [
        "df = df[df['total_time'].between(10000,1000000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F3joLmLjXPY2"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import style\n",
        "style.use(\"seaborn-darkgrid\")\n",
        "df[['total_time']].plot(kind='hist',bins=20)\n",
        "plt.title('Test completion times')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MJKV9P-NXPY2"
      },
      "cell_type": "code",
      "source": [
        "# List the redundant cols such as longitude and latitudee\n",
        "drop_cols=list(df.columns[50:107])+['lat_appx_lots_of_err','long_appx_lots_of_err']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QceC9_gZXPY3"
      },
      "cell_type": "code",
      "source": [
        "# Drop the redundant cols\n",
        "df=df.drop((drop_cols), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "t9f2zlsBXPY3"
      },
      "cell_type": "code",
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_l1-RP7XXPY3"
      },
      "cell_type": "code",
      "source": [
        "# List the number of unique countries, count them\n",
        "countries = df['country'].unique()\n",
        "len(countries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aP86EdH_XPY4"
      },
      "cell_type": "code",
      "source": [
        "# A list of all EU countries, count them\n",
        "EU = [\"AT\", \"BE\", \"BG\", \"CY\", \"CZ\", \"DE\", \"DK\", \"EE\", \"ES\", \"FI\", \"FR\", \"GB\", \"GR\", \"HR\", \"HU\", \"IE\", \"IT\", \"LT\", \"LU\", \"LV\", \"MT\", \"NL\", \"PL\", \"PT\", \"RO\", \"SE\", \"SI\", \"SK\"]\n",
        "len(EU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jJciya4qXPY4"
      },
      "cell_type": "code",
      "source": [
        "# Check if all EU countries are in the data\n",
        "intersection = set(EU).intersection(set(countries))\n",
        "len(intersection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "B1741fbhXPY5"
      },
      "cell_type": "code",
      "source": [
        "# Limit the analysis to EU countries\n",
        "df = df.loc[df['country'].isin(EU)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "XV2r904OXPY6"
      },
      "cell_type": "code",
      "source": [
        "# Count responses by country\n",
        "df['country'].value_counts()[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "euCD5qd9XPY6"
      },
      "cell_type": "code",
      "source": [
        "# This gives us percentage of responses from each country\n",
        "df['country'].value_counts(normalize=True) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Vj85x-OmXPY7"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePjVhRjaXPY7"
      },
      "cell_type": "markdown",
      "source": [
        "# FEATURE AGGREGATION"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zgI8VdBHXPZK"
      },
      "cell_type": "code",
      "source": [
        "# Create an aggregated feature for each of the five personality dimensions.\n",
        "# They will average the 10 answers across the dimension.\n",
        "\n",
        "# Extraversion\n",
        "EXT = list(df.columns[:10])\n",
        "# Emotional Stability\n",
        "EST = list(df.columns[10:20])\n",
        "# Agreeableness\n",
        "AGR = list(df.columns[20:30])\n",
        "# Conscientiousness\n",
        "CSN = list(df.columns[30:40])\n",
        "# Openness\n",
        "OPN = list(df.columns[40:50])\n",
        "\n",
        "dimensions = [EXT,EST,AGR,CSN,OPN]\n",
        "dimension_averages=[\"extraversion\",\"emotional_stability\",\n",
        "       \"agreeableness\",\"conscientiousness\",\"openness\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_84CdE1nXPZK"
      },
      "cell_type": "code",
      "source": [
        "for d in range(len(dimensions)):\n",
        "    df[dimension_averages[d]] = df[dimensions[d]].mean(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QDqFVvb5XPZL"
      },
      "cell_type": "markdown",
      "source": [
        "# ANALYSE THE DATA"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "u_hDa7ftXPZL"
      },
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-fjsZz8yXPZM"
      },
      "cell_type": "code",
      "source": [
        "# Analyse the aggregated features\n",
        "df[dimension_averages].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qc3dyiW0XPZM"
      },
      "cell_type": "markdown",
      "source": [
        "# VISUALISE THE DATA"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hHf3O_J8XPZM"
      },
      "cell_type": "code",
      "source": [
        "# Use a boxlot to visualise the 5 variables\n",
        "# This method will give us a good overview of the distribution across the variables\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "#reset default parameters\n",
        "sns.set()\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.set(font_scale=1.5)\n",
        "sns.boxplot(data=df[dimension_averages]);\n",
        "plt.title(\"Average characteristics of European citizens\",fontsize=22)\n",
        "plt.savefig('avg_char.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PzYzuIypXPZN"
      },
      "cell_type": "code",
      "source": [
        "#reset default parameters\n",
        "sns.set()\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Visualise the correlation\n",
        "corr=df[dimension_averages].corr()\n",
        "mask = np.triu(corr)\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(df[dimension_averages].corr(),\n",
        "            vmin=0,\n",
        "            vmax=1,\n",
        "            annot = True,\n",
        "            square=True,\n",
        "            mask=mask,\n",
        "            cbar=True,\n",
        "            cmap='Blues')\n",
        "plt.title('Correlation between personality traits',fontsize=22)\n",
        "plt.savefig('correlations.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8U-Wwtd0XPZN"
      },
      "cell_type": "code",
      "source": [
        "# Subset df to only those with country GB, PL\n",
        "gb = df.loc[df['country']==\"GB\"]\n",
        "pl = df.loc[df['country']==\"PL\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_K_idhWQXPZN"
      },
      "cell_type": "code",
      "source": [
        "# Limit the analysis to two countries and averages across 5 dimensions\n",
        "gb = gb[gb.columns[-6:]]\n",
        "pl = pl[pl.columns[-6:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LPOUcTxOXPZO"
      },
      "cell_type": "code",
      "source": [
        "def transpose_table(df, col_list):\n",
        "    \"\"\"\n",
        "    INPUT\n",
        "        df - a dataframe holding the col_list columns\n",
        "        col_list- columns that we want to transpose into rows\n",
        "\n",
        "    OUTPUT\n",
        "        new_df- a transposed dataframe.\n",
        "    \"\"\"\n",
        "    new_df = defaultdict(int)\n",
        "    for i in col_list:\n",
        "        new_df[i]=df[i].mean()\n",
        "    new_df = pd.DataFrame(pd.Series(new_df)).reset_index()\n",
        "    new_df.rename(columns={'index': 'personality', 0: 'average'}, inplace=True)\n",
        "    new_df.set_index('personality', inplace=True)\n",
        "    return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "a3xW1hfSXPZO"
      },
      "cell_type": "code",
      "source": [
        "dimension_averages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "XsSya3KnXPZO"
      },
      "cell_type": "code",
      "source": [
        "gb_avg = transpose_table(gb,dimension_averages)\n",
        "pl_avg = transpose_table(pl,dimension_averages)\n",
        "comp_df = pd.merge(gb_avg, pl_avg, left_index=True, right_index=True)\n",
        "comp_df.columns = ['gb_avg', 'pl_avg']\n",
        "comp_df['value_difference'] = comp_df['gb_avg'] - comp_df['pl_avg']\n",
        "comp_df.style.bar(subset=['value_difference'], align='mid', color=['#d65f5f', '#5fba7d'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "nBRWtmX6XPZP"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "w6sMxV8xXPZP"
      },
      "cell_type": "code",
      "source": [
        "# Add binary column to indicate if Great Britain\n",
        "df['is_gb'] = df['country'].apply(lambda x: 1 if x =='GB' else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NiCYv6K1XPZQ"
      },
      "cell_type": "markdown",
      "source": [
        "# MODELLING"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-fuXsPbqXPZQ"
      },
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "df_ml = df.copy()\n",
        "\n",
        "to_drop =[\"country\",\"total_time\"]\n",
        "          #+[\"extraversion\",\"emotional_stability\",\"agreeableness\",\"conscientiousness\",\"openness\"]\n",
        "\n",
        "# Delete old column indicating country\n",
        "df_ml = df_ml.drop(columns=to_drop)\n",
        "\n",
        "# Shuffle the data to ensure that split is fair\n",
        "df_ml = df_ml.sample(n=len(df_ml),random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bVwmq1L4XPZQ"
      },
      "cell_type": "markdown",
      "source": [
        "# CORRELATIONS"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VS6CCBUYXPZR"
      },
      "cell_type": "code",
      "source": [
        "corr_data = pd.DataFrame(df_ml.corr()['is_gb'][:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0drTLXN4XPZR"
      },
      "cell_type": "code",
      "source": [
        "corr_data = corr_data.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yQrVTeIlXPZR"
      },
      "cell_type": "code",
      "source": [
        "corr_data = corr_data.sort_values(by=['is_gb'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YQ39wIOaXPZS"
      },
      "cell_type": "code",
      "source": [
        "corr_data[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "obNd77bLXPZS"
      },
      "cell_type": "code",
      "source": [
        "corr_data[-4:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8PNaA39DXPZS"
      },
      "cell_type": "code",
      "source": [
        "top_correlation = corr_data.sort_values('is_gb', ascending=False).head(10)['index'].to_list()\n",
        "least_correlation = corr_data.sort_values('is_gb', ascending=False).tail(5)['index'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "i2YJRr_zXPZT"
      },
      "cell_type": "code",
      "source": [
        "# Count the outcome variables to identify the baseline\n",
        "positives = len(df.loc[df_ml['is_gb']==1])\n",
        "negatives = len(df.loc[df_ml['is_gb']==0])\n",
        "1-(positives/(positives+negatives))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sVKGh2UaXPZT"
      },
      "cell_type": "code",
      "source": [
        "# Select the dependent variable\n",
        "Y = df_ml['is_gb']\n",
        "X = df_ml.drop('is_gb',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TfK5Wd4lXPZT"
      },
      "cell_type": "code",
      "source": [
        "# Split the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FVCxjr2MXPZU"
      },
      "cell_type": "markdown",
      "source": [
        "# XGBOOST"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WTGNjbcOXPZU"
      },
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Instantiate the model\n",
        "xgb_model = xgb.XGBClassifier(learning_rate=0.05,\n",
        "              max_depth=3,\n",
        "              gamma=0.08435594187707007,\n",
        "              colsample_bytree=0.5336629698328548,\n",
        "              n_estimators=1000,\n",
        "              objective='binary:logistic',\n",
        "              random_state=42)\n",
        "\n",
        "# fit model to training data\n",
        "xgb_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8aeJax4JXPZV"
      },
      "cell_type": "code",
      "source": [
        "# make predictions for test data\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Y7y9FswJXPZV"
      },
      "cell_type": "code",
      "source": [
        "# Find optimal threshold\n",
        "thresholds=(np.linspace(0.45,0.50,20))\n",
        "for t in thresholds:\n",
        "    predictions=xgb_model.predict_proba(X_test)[:,1]>t\n",
        "    print(\"AUC for threshold\",t,\":\",\n",
        "         roc_auc_score(y_test, predictions))\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(\"XGB Classifier accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mjUK2BpuXPZW"
      },
      "cell_type": "code",
      "source": [
        "69/61"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KipItNN4XPZW"
      },
      "cell_type": "code",
      "source": [
        "# Check the most important features\n",
        "importance = xgb_model.get_booster().get_score(importance_type= 'gain')\n",
        "sorted(importance.items(), key=lambda x:x[1],reverse=True)[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJzwcLWKXPZW"
      },
      "cell_type": "markdown",
      "source": [
        "<b> Question code mapping\n",
        "    \n",
        "AGR3: I insult people\n",
        "    \n",
        "CSN8: I shirk my duties\n",
        "    \n",
        "EST9: I get irritated easily"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1Q6XGm9oXPZX"
      },
      "cell_type": "code",
      "source": [
        "gb_df = df.loc[df['is_gb']==1]\n",
        "eu_df = df.loc[df['is_gb']==0]\n",
        "comp_metrics = ['AGR3','CSN8','EST9']\n",
        "\n",
        "gb_df = transpose_table(gb_df,comp_metrics)\n",
        "eu_df = transpose_table(eu_df,comp_metrics)\n",
        "comp_df = pd.merge(gb_df, eu_df, left_index=True, right_index=True)\n",
        "comp_df.columns = ['gb_avg','eu_avg']\n",
        "comp_df['value_difference'] = comp_df['gb_avg'] - comp_df['eu_avg']\n",
        "comp_df.style.bar(subset=['value_difference'], align='mid', color=['#d65f5f', '#5fba7d'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (gajdulj)",
      "language": "python",
      "name": "gajdulj"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "EDA, agg features, XGB nationality prediction ",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}